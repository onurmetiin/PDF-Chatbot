# -- A# Soruya en uygun yanÄ±tÄ± Google Gemini LLM ile oluÅŸturmak ve ekranda gÃ¶stermekA UYGULAMA DOSYASI (STREAMLÄ°T ARAYÃœZÃœ) --

# KulanÄ±cÄ±dan PDF dosyasÄ±nÄ± almak
#Â PDF'ten metin Ã§Ä±karma ve parÃ§alama iÅŸlemini baÅŸlatmak
#Â VektÃ¶r veritabanÄ± oluÅŸturma
#Â KullanÄ±cÄ±dan bir soru almak
#Â Soruya en uygun yanÄ±tÄ± OpenAI LLM ile oluÅŸturmak ve ekranda gÃ¶stermek

import streamlit as st  # Streamlit modÃ¼lÃ¼ (Web uygulamasÄ± iÃ§in arayÃ¼z kÃ¼tÃ¼phanesi)
from pdf_utils import extract_text_from_pdf, split_text_into_chunks  # PDF okuma ve metin bÃ¶lme fonksiyonlarÄ±
from rag_pipeline import create_vector_db, ask_question  # RAG (Retrieval-Augmented Generation) iÅŸlemleri (Embedding oluÅŸturma ve GPT Ã¼zerinden yanÄ±t alma)

# Streamlit uygulamasÄ± iÃ§in sayfa yapÄ±landÄ±rmasÄ±
st.set_page_config(page_title="ğŸ“„ PDF ChatBot", layout="wide")
st.title("ğŸ“„ Chat with your PDF document!")  # Uygulama baÅŸlÄ±ÄŸÄ±
st.caption("PDF Document-based artificial intelligence assistant powered by Google Gemini") # Uygulama aÃ§Ä±klamasÄ±


# KullanÄ±cÄ±dan PDF dosyasÄ± yÃ¼klemesi istenir
uploaded_file = st.file_uploader("Upload your PDF file", type="pdf")  # KullanÄ±cÄ±dan PDF dosyasÄ± yÃ¼klemesi istenir
if uploaded_file is not None:
    st.success("Your PDF file uploaded!")  # Dosya yÃ¼klendiÄŸinde baÅŸarÄ± mesajÄ± gÃ¶sterilir
    
    
    # PDF dosyasÄ± yÃ¼klendiÄŸinde metin Ã§Ä±karma ve vektÃ¶r veritabanÄ± oluÅŸturma iÅŸlemleri baÅŸlatÄ±lÄ±r
    with st.spinner("PDF iÅŸleniyor..."): #KullanÄ±cÄ±ya yÃ¼kleniyor animasyonu gÃ¶sterir
    
        text = extract_text_from_pdf(uploaded_file)  # PDF dosyasÄ±ndan metin Ã§Ä±karÄ±lÄ±r
        chunks = split_text_into_chunks(text) # Metin, belirli boyutlarda parÃ§alara bÃ¶lÃ¼nÃ¼r
        vector_db = create_vector_db(chunks)  # Metin parÃ§alarÄ±ndan vektÃ¶r veritabanÄ± oluÅŸturulur
    
    
    # KullanÄ±cÄ±dan bir soru girmesi istenir
    question = st.text_input("ğŸ“¥ What do you want to learn about in this file?")
    if question:
        with st.spinner("Document processing..."):
            answer = ask_question(vector_db, question)
            st.markdown(f"Answer: \n\n {answer}")  # Google Gemini LLM tarafÄ±ndan oluÅŸturulan yanÄ±t ekranda gÃ¶sterilir        
        
        
# Uygulama Ã§alÄ±ÅŸtÄ±rmak iÃ§in terminalde ÅŸu komutu kullanÄ±n:
# streamlit run main.py